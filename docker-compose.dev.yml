version: "3.8"
services:
  app:
    image: app-server:1.0.0-dev
    container_name: app-server-dev
    build:
      context: .
      dockerfile: docker/nest/dev.dockerfile
    working_dir: /home/node/workspace
    command: npm run start:debug
    restart: unless-stopped
    tty: true
    volumes:
      - .:/home/node/workspace
      - /home/node/workspace/node_modules
    networks:
      -  app-server-network
    env_file:
      - .env.dev
    ports:
      - '8030:8003'
      - '85:80'

  redis:
    container_name: app-redis
    image: redis
    restart: unless-stopped
    ports:
      - 6383:6379
    command: redis-server --save 20 1 --loglevel warning
    networks:
      - app-server-network
    volumes:
      - app-redis:/data

  database:
    container_name: app-database
    image: postgres:14.1
    restart: unless-stopped
    volumes:
      - app-database:/var/lib/postgres
      - ./docker/postgres:/docker-entrypoint-initdb.d
    environment:
      POSTGRES_USER: root
      POSTGRES_PASSWORD: 123456
    ports:
      - 5446:5432
    networks:
      - app-server-network

  timescale-database:
    container_name: app-timescale-database
    image: timescale/timescaledb:2.6.1-pg14
    platform: linux/amd64
    restart: unless-stopped
    volumes:
      - app-timescale-database:/var/lib/postgresql/data
      - ./docker/timescaleDB:/docker-entrypoint-initdb.d
    environment:
      # TIMESCALEDB_TELEMETRY: on
      POSTGRES_USER: root
      POSTGRES_PASSWORD: 123456
      PGPORT: 5433
    ports:
      - 5449:5433
    networks:
      - app-server-network

  vector-database:
    container_name: app-vector-database
    image: ankane/pgvector
    ports:
      - 5445:5434
    volumes:
      - app-vector-database:/var/lib/postgres
      #- ./docker/postgres:/docker-entrypoint-initdb.d
    environment:
      POSTGRES_USER: root
      POSTGRES_PASSWORD: 123456
      PGPORT: 5434
      POSTGRES_DB: vector
    networks:
      - app-server-network

  pubsub-emulator:
    container_name: app-server-pubsub
    image: google/cloud-sdk:emulators
    ports:
      - "8089:8085"
    environment:
      - PUBSUB_EMULATOR_HOST=0.0.0.0:8085
    command: gcloud beta emulators pubsub start --host-port=0.0.0.0:8085
    platform: linux/amd64
    networks:
      - app-server-network

  etcd:
    container_name: app-milvus-etcd
    image: quay.io/coreos/etcd:v3.5.5
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 20s
      retries: 3
    volumes:
      # - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/etcd:/etcd
      - app-etcd:/etcd
    networks:
      - app-server-network

  minio:
    container_name: app-milvus-minio
    image: minio/minio:RELEASE.2023-03-20T20-16-18Z
    environment:
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
    ports:
      - "9001:9001"
      - "9000:9000"
    command: minio server /minio_data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    volumes:
      - app-minio:/minio_data
      # - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/minio:/minio_data
    networks:
      - app-server-network

  milvus:
    container_name: app-milvus-standalone
    image: milvusdb/milvus:v2.3.12
    command: ["milvus", "run", "standalone"]
    security_opt:
    - seccomp:unconfined
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      start_period: 90s
      timeout: 20s
      retries: 3
    ports:
      - "19530:19530"
      - "9091:9091"
    depends_on:
      - "etcd"
      - "minio"
    platform: linux/amd64
    volumes:
      # - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus
      - app-milvus:/var/lib/milvus
    networks:
      - app-server-network

  attu:
    container_name: app-milvus-visualize
    image: zilliz/attu:v2.3.10
    ports:
      - "4567:3000"
    environment:
      - MILVUS_URL=milvus:19530
    networks:
      - app-server-network

  milvus-cli:
    container_name: app-milvus-cli
    image: zilliz/milvus_cli:latest
    command: tail -f /dev/null
    platform: linux/amd64
    tty: true           # <-- This option
    networks:
      - app-server-network


  langfuse-server:
    container_name: app-langfuse
    image: langfuse/langfuse:2
    ports:
      - "1234:3000"
    environment:
      - DATABASE_URL=postgresql://root:123456@database:5432/langfuse
      - NEXTAUTH_SECRET=mysecret
      - SALT=mysalt
      - NEXTAUTH_URL=http://localhost:3000
      - TELEMETRY_ENABLED=${TELEMETRY_ENABLED:-true}
      - LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES=${LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES:-false}
    platform: linux/amd64
    networks:
      - app-server-network

  # # NOT CUDA -==> for MAC
  # llama-gpt-api:
  #   # Pin the image to llama-cpp-python 0.1.78 to avoid ggml => gguf breaking changes
  #   image: ghcr.io/abetlen/llama-cpp-python:latest@sha256:b6d21ff8c4d9baad65e1fa741a0f8c898d68735fff3f3cd777e3f0c6a1839dd4
  #   restart: on-failure
  #   volumes:
  #     - './docker/models:/models'
  #     - './docker/cuda:/cuda'
  #   ports:
  #     - 3001:8000
  #   environment:
  #     MODEL: '/models/${MODEL_NAME:-llama-2-7b-chat.bin}'
  #     MODEL_DOWNLOAD_URL: '${MODEL_DOWNLOAD_URL:-https://huggingface.co/TheBloke/Nous-Hermes-Llama-2-7B-GGML/resolve/main/nous-hermes-llama-2-7b.ggmlv3.q4_0.bin}'
  #     N_GQA: '${N_GQA:-1}'
  #     USE_MLOCK: 1
  #   cap_add:
  #     - IPC_LOCK
  #   command: '/bin/sh /cuda/run.sh'
  #   networks:
  #     - app-server-network

  # https://github.com/getumbrel/llama-gpt/blob/master/docker-compose-cuda-ggml.yml
  llama-gpt-api-cuda-ggml:
    container_name: app-llama-gpt
    build:
      context: ./docker/cuda
      dockerfile: gglm.Dockerfile
    restart: on-failure
    volumes:
      - './docker/models:/models'
      - './docker/cuda:/cuda'
    ports:
      - 3001:8000
    environment:
      MODEL: '/models/${MODEL_NAME:-llama-2-7b-chat.bin}'
      MODEL_DOWNLOAD_URL: '${MODEL_DOWNLOAD_URL:-https://huggingface.co/TheBloke/Nous-Hermes-Llama-2-7B-GGML/resolve/main/nous-hermes-llama-2-7b.ggmlv3.q4_0.bin}'
      N_GQA: '${N_GQA:-1}'
      USE_MLOCK: 1
    cap_add:
      - IPC_LOCK
      - SYS_RESOURCE
    command: '/bin/sh /cuda/run.sh'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - app-server-network

  llama-gpt-ui:
    # TODO: Use this image instead of building from source after the next release
    container_name: app-llama-gpt-ui
    image: 'ghcr.io/getumbrel/llama-gpt-ui:latest'
    # build:
    #   context: ./ui
    #   dockerfile: Dockerfile
    ports:
      - 3000:3000
    restart: on-failure
    environment:
      - 'OPENAI_API_KEY=sk-XXXXXXXXXXXXXXXXXXXX'
      - 'OPENAI_API_HOST=http://llama-gpt-api-cuda-ggml:8000'
      - 'DEFAULT_MODEL=/models/${MODEL_NAME:-llama-2-7b-chat.bin}'
      - 'NEXT_PUBLIC_DEFAULT_SYSTEM_PROMPT=${DEFAULT_SYSTEM_PROMPT:-"You are a helpful and friendly AI assistant. Respond very concisely."}'
      - 'WAIT_HOSTS=llama-gpt-api-cuda-ggml:8000'
      - 'WAIT_TIMEOUT=${WAIT_TIMEOUT:-3600}'
    networks:
      - app-server-network

  elasticsearch:
    container_name: app-elasticsearch
    image: elasticsearch:8.7.0
    environment:
      - xpack.security.enabled=false
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    networks:
      - app-server-network
    ports:
      - 9200:9200

  kibana:
    container_name: app-kibana
    image: kibana:8.7.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200/
    networks:
      - app-server-network
    depends_on:
      - elasticsearch
    ports:
      - 5601:5601


  rabbitmq:
    image: rabbitmq:3.6.14-management
    container_name: app-rabbitmq
    # healthcheck:
    #   test: ['CMD', 'curl', '-f', 'http://127.0.0.1:5672']
    #   interval: 30s
    #   timeout: 10s
    #   retries: 5
    ports:
      - 5672:5672
      - 15672:15672
    environment:
      - RABBITMQ_DEFAULT_USER=root
      - RABBITMQ_DEFAULT_PASS=123456
    networks:
      - app-server-network
      
networks:
  app-server-network:
    driver: bridge

volumes:
  app-redis:
    driver: local
  app-database:
    driver: local
  app-timescale-database:
    driver: local
  app-vector-database:
    driver: local
  app-milvus:
    driver: local
  app-minio:
    driver: local
  app-etcd:
    driver: local

# https://docs.timescale.com/self-hosted/latest/install/installation-docker/

# psql -U root -h localhost
# \c app_timescale
# CREATE EXTENSION IF NOT EXISTS timescaledb;
# psql -U root -h localhost -d app_timescale
# \dx
# select create_hypertable('prices','time');
# drop table prices;